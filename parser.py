import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from openpyxl import Workbook
from bs4 import BeautifulSoup
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
import os
import os
import pickle
# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ---
def assign_category(name):
    if not name:
        return "–ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û"
    name_lower = name.lower()
    if any(k in name_lower for k in ["ÏÑ†ÌÅ¨Î¶º", "sun screen", "ÏÑ† ","sun","ÏÑ† ÌÅ¨Î¶º" , "spf", "sun cream","sun stick", "sun care","ÏÑ†Ïä§Ìã±"]):
        return "SUN CARE I –ó–ê–©–ò–¢–ê –û–¢ –°–û–õ–ù–¶–ê"
    if any(k in name_lower for k in ["ÎØ∏ÏÖÄÎùº", "micellar","ENZYME", "ÌïÑÎßÅ","Cleanser", "peeling","ÎπÑÎàÑ","soup","ÏΩîÌå©","nose pack", "ÌÅ¥Î†åÏßï","Î¶¨Î¨¥Î≤Ñ ","remover", "cleansing","ÌïÑ Ïò§ÌîÑ Ìå© ","peel off pack", "Ìèº", "foam", "ÌïÑÎßÅ Ï†§", "peeling gel", "ÌÅ¥Î†åÏ†Ä Ïò§Ïùº", "cleanser oil ", "Ïò§Ïùº ÌÅ¥Î†åÏ†Ä", "oil cleanser", "ÎßàÏùºÎìú", "mild", "ÏõåÌÑ∞","cleansing water", "water wash"]):
        return "CLEANSING I –û–ß–ò–©–ï–ù–ò–ï"
    if any(k in name_lower for k in ["Ïï∞Ìîå", "ampoule","ÏßÑÏï°","Ïä§ÌÇ®","Ïú†Ïó∞Ïï°","ÏóêÎ©ÄÏÖò","Ïú†Ïó∞Ïàò","patch","pad","REEDLE SHOT","pack","source","Moisturizer", "ampule","Î©ÄÌã∞Î∞§", "multi balm","ÏóêÎ©ÄÏ†Ñ", "ÏÜåÌîÑÎÑà","softner", "ÌÅ¨Î¶º", "cream", "ÌÜ†ÎÑà","ÏïÑÏù¥Ìå®Ïπò","eye patch","Î©ÄÌã∞ Î∞§ ", "toner","ÏóêÎ©ÄÏ†º","emulsion","ÏóëÏä§Ìä∏Îùº Ïï°ÌÑ∞","ÏàòÏï°","Î¶¨ÌîÑÏÉ∑", "Ïú†Ïï°", "ÎßàÏä§ÌÅ¨", "mask", "ÏóêÏÑºÏä§", "essence","Ïò¥ÎØÄ Ïò¨Ïù∏Ïõê", "ÏÑ∏Îüº", "serum", "ÏïÑÏù¥ÌÅ¨Î¶º", "eye cream", "eye serum", "ÌïòÏù¥ÎìúÎ†àÏù¥ÌåÖ", "hydrating", "ÎπÑÌÉÄ", "vitamin", "Î¶¨ÌîÑÌåÖ", "lifting", "ÎØ∏Î∞±", "whitening", "brightening", "ÏàòÎî©", "soothing", "balm", "concentrate","Ìå®Îìú","ÎßÅÌÅ¥ ÏßÑÏï°Í≥†","ÏàòÎ∂ÑÌå©","Ïï∞ÌíÄÏò§Ïùº","ÏßÑÏï° Ïò§Ïùº","ÏïÑÏù¥Î¶¨ÌîÑÌä∏","Î©ÄÌã∞Ïä§Ìã±","Î∞∏Îü∞ÏÑú"]):
        return "SKIN CARE I –£–•–û–î –ó–ê –õ–ò–¶–û–ú"
    if any(k in name_lower for k in ["Î∞îÎîî", "body", "Î°úÏÖò", "lotion","Ïó¨ÏÑ± Ï≤≠Í≤∞Ï†ú", "Ïä§ÌÅ¨ÎüΩ", "scrub", "Î∞îÎîîÏõåÏãú","ÎÑ•", "body wash", "ÏÉ§ÏõåÏ†§", "shower gel","Ïó¨ÏÑ±Ï≤≠Í≤∞Ï†ú"]):
        return "BODY CARE I –£–•–û–î –ó–ê –¢–ï–õ–û–ú"
    if any(k in name_lower for k in ["ÏÉ¥Ìë∏", "shampoo","ÏôÅÏã± Îß§ÎãàÌÅêÏñ¥","ÎØ∏ÏüùÏÑº","Ìó§Ïñ¥Ïª§Î≤Ñ","LPP Ìä∏Î¶¨Ìä∏","ÏïÑÎ•¥ÎìúÌè¨ Ïä§ÌîÑÎ†àÏù¥","ÏóºÏÉâ", "Ïª®ÎîîÏÖîÎÑà","ÏùºÏßÑ ÏºÄÎ°† ÏãúÏä§ÌÖåÏù∏ Ïõ®Ïù¥Î∏å","ÌçºÌì∏ Î¶∞Ïä§", "conditioner","ÏïÑÏù¥ ÌåîÎ†àÌä∏", "Î¶∞Ïä§","Ìä∏Î¶¨Ìä∏Î®ºÌä∏","hair treatment", "Ìó§Ïñ¥ Î¶∞Ïä§","Ïø®ÎßÅ ÌÜ†Îãâ","ÏºÄÎùºÌã¥", "Ìó§Ïñ¥ÏπºÎùº","ÌÅ¨Î¶¨Îãâ ÏπºÎùº"," Ìó§Ïñ¥ ÏπºÎùº"," Ìó§Ïñ¥","Ïä§ÌÉÄÏùºÎßÅ Î¨¥Ïä§ ","ÏÖãÌåÖ Ïä§ÌîÑÎ†àÏù¥", "hair", "treatment", "Ìó§Ïñ¥Ìå©","ÏãúÏä§ÌÖåÏù∏","Ìó§Ïñ¥ÎπÑÎπÑ", "hair pack","ÏÉàÏπò", "Ìó§Ïñ¥Ïò§Ïùº", "hair oil"]):
        return "HAIR CARE I –£–•–û–î –ó–ê –í–û–õ–û–°–ê–ú–ò"
    if any(k in name_lower for k in ["Î¶Ω", "lip", "ÌååÏö¥Îç∞Ïù¥ÏÖò","jelly stick", "foundation", "Î∏îÎü¨ÏÖî", "blush","ÏÑÄÎèÑ ÌåîÎ†àÌä∏","shedow", "ÏÑÄÎèÑÏö∞"," ÎßàÏä§Ïπ¥Îùº ","mascara", "ÎπÑÎπÑ","ÌîÑÎùºÏù¥Î®∏","Í≥®Îì† Î≤†Ïù¥Ïä§","Î≤†Ïù¥Ïä§","bb cream", "ÏïÑÏù¥Î∏åÎ°úÏö∞","eye brow", "Ìå©ÏÜî","eye liner","ÏïÑÏù¥ÎùºÏù¥ÎÑà","Î∏îÎü¨Ïâ¨","blasher","ÏïÑÏù¥Î∏åÎ°úÏö∞ ÌéúÏä¨","pencil", "Î¨ºÍ¥ëÍ∏ÄÎ°úÏö∞"," glow" , "Ïª®Ïã§Îü¨","concealer","ÌéúÏä¨ ","Ìéú ÎùºÏù¥ÎÑà","Ìéú ÎùºÏù¥ÎÑà","liner", "Î∏åÎü¨Ïâ¨ ÎùºÏù¥ÎÑà","ÌïòÏù¥ÎùºÏù¥ÌÑ∞", "hilighter", "ÏâêÎèÑÏö∞", "eyeshadow", "Í∏ÄÎ°úÏä§", "ÏïÑÏù¥ÏÑÄÎèÑ", "Ìà¨Ïõ®Ïù¥ÏºÄÏùµ", "two way cake", "Ïä§ÌÇ®Ïª§Î≤Ñ","cover","eye shadow", "Î©îÏù¥ÌÅ¨ÏóÖ", "make up","Ìå©Ìä∏","pact","ÌååÏö∞Îçî","powder"," ÌîºÎãàÏâ¨","finish", "base","Ïª®Ìà¨Ïñ¥ "," ÎØ∏Ïä§Ìä∏", "Ïø†ÏÖò", "cushion", "Ìã¥Ìä∏", "tint","Î≤†Ïù¥Ïä§ ÌïëÌÅ¨"]):
        return "MAKE UP I –î–ï–ö–û–†–ê–¢–ò–í–ù–´–ô –ú–ê–ö–ò–Ø–ñ"
    if any(k in name_lower for k in ["ÏÑ∏Ìä∏", "set", "Í∏∞ÌöçÏÑ∏Ìä∏","Í∏∞Ìöç", "special set", "Ìå®ÌÇ§ÏßÄ", "package", "Ïª¨Î†âÏÖò", "collection","3Ï¢Ö","kit","ÌÇ§Ìä∏","ÏÑ∏Ìä∏","Í∏∞ÌíàÏÑ∏Ìä∏","Í∂ÅÏ§ëÏÑ∏Ìä∏","Í∏∞Ìöç","Ï¢ÖÏÑ∏Ìä∏"]):
        return "SKIN CARE SET I –£–•–û–î–û–í–´–ï –ù–ê–ë–û–†–´"
    if any(k in name_lower for k in ["ÎÇ®ÏÑ±", "men","Î≥¥Îãå", "Ïä§ÌîÑÎ†àÏù¥ ÎìúÎùºÏù¥ ÏûÑÌå©Ìä∏","Ìè¨Îß®", " Ïï†ÌîÑÌÑ∞ ÏâêÏù¥Î∏å ", "for men","ÏâêÏù¥Î∏å","homme"]):
        return "FOR MEN / –î–ª—è –º—É–∂—á–∏–Ω"
    if any(k in name_lower for k in ["ÏÉòÌîå", "sample", "ÎØ∏Îãà", "mini", "Ìä∏ÎûòÎ∏î", "travel"]):
        return "SAMPLE | –ü–†–û–ë–ù–ò–ö–ò"
    if any(k in name_lower for k in ["Í±¥Í∞ïÍ∏∞Îä•ÏãùÌíà", "supplement", "ÎπÑÌÉÄÎØº", "vitamin", "Ïò§Î©îÍ∞Ä", "omega", "ÌîÑÎ°úÎ∞îÏù¥Ïò§Ìã±Ïä§", "probiotic","boto"]):
        return "–ë–ê–î–´"
    if any(k in name_lower for k in ["ÏΩîÎ°±","Îç∞Ïò§ÎìúÎûÄÌä∏","bag","perfume","ÏΩîÏπò","Î∂ÄÏâêÎ°†","Î©îÎîîÏïà","ÏáºÌïëÎ∞±","Ìñ•Ïàò" "Ìè¥Î°ú","brush","Î©îÎ•¥ÏÑ∏Îç∞Ïä§ Î≤§Ï∏†"," ÏπòÏïΩ ","ÏóòÎ¶¨ÏûêÎ≤†Ïä§ÏïÑÎç¥ ","ÏÉ§ÏõåÎ≥º","Ï£ºÎ∞©ÏÑ∏Ï†ú","ÏÑ∏Ï†ïÏ†ú","Í≥µÏö©Í∏∞","Ìó§Ïñ¥Î°§","Î≤†Î•¥ÏÇ¨Ï≤¥","Î≤ÑÎ≤ÑÎ¶¨","Î≤ÑÎ∏îÏ†úÎ°ú","Íµ¨Ï∞å ","ÏΩîÍ∞ÄÏúÑ","Ï°±ÏßëÍ≤å","Ïò§Îç∞ÌçºÌì∏","ÏåçÍ∫ºÌíÄ"," toothpast","ÌôîÏû•ÏÜú","Ïä§ÌîÑÎßÅÎ∞¥Îìú","4D ÌéòÏù¥ÏÖú","Î©îÎîîÏïà "," Î∑∞Ìã∞ Î∞î","Î©¥Î¥â","Î∂àÍ∞ÄÎ¶¨","ÏÜêÌÜ±Ï†ÑÏö©","Î¨ºÌã∞Ïäà","ÎïåÎπÑÎàÑ","Î™ΩÎ∏îÎûë","Î°§Î¶¨ÌÉÄ","ÏÑ∏ÌÉÅÎπÑÎàÑ","Í≥†Î¨¥Ïû•Í∞ë","Ïî®ÏºÄÏù¥","ÏóêÏä§Ìã∞Î°úÎçî","ÌéòÎ¶¨Ïò§","Ï†úÏäµÌòÅÎ™Ö","Ïõ∞Ìà¨Ïä§","ÏóòÏßÄ","ÏÜêÏÜåÎèÖÏ†ú","ÏßÄÎØ∏Ï∂î","ÏóòÏßÄ ÌÖåÌÅ¨","ÎÑ§Ïùº Ïä§Ìã∞Ïª§","ÎöúÏôàÎ†õ","Ïî®ÏºÄÏù¥","ÎûëÎ∞©","Ìè¥Î°ú","SPPC","ÏäµÍ∏∞Ï†úÍ±∞Ï†ú","Í∞ÅÌã∞Ïäà","Ìè¥Î°ú Ïä§Ìè¨Ï∏†","Ïû•ÏïÑÎñº","ÌÇ§ÏπúÌÉÄÏò¨","2080","ÏúÑÏÉùÎ°§Î∞±","Î™®Ïä§ÌÇ§ÎÖ∏ ","ÎîîÌì®Ï†Ä","ÏûÖÏöïÏ†ú","Í≤êÏ°∞","ÎèåÏ≤¥ Ïï§ Í∞ÄÎ∞îÎÇò","ÏïÑÎ¶¨ÏïÑÎÇò Í∑∏ÎûÄÎç∞","ÌçºÌì∏","ÏóêÎ•¥Î©îÏä§","ÏÉ§ÏõåÏΩîÎ°±","Ï°¥ Î∞îÎ∞îÌÜ†Ïä§","Î°úÌéòÏä§ Îß§ÎãàÌÅêÏñ¥","Îß§ÎãàÌÅêÏñ¥"]):
        return "–¢–û–í–ê–†–´ –î–õ–Ø –î–û–ú–ê –ò –ó–î–û–†–û–í–¨–Ø"
    return "–ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û"

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±—Ä–µ–Ω–¥–æ–º ---
def extract_brand_name(brand_url):
    brand_cd = brand_url.split("brand_cd=")[-1]
    brand_name_map = {
    "BR000357": "9Wishes",
    "BR001115": "ABEREDE",
    "BR000311": "Abib",
    "BR000067": "ACWELL",
    "BR000473": "AESTURA",
    "BR000457": "AHEADS",
    "BR000487": "AIRIVE",
    "BR000811": "AKF",
    "BR000502": "ALETHEIA",
    "BR001097": "ALLIONE",
    "BR000081": "Amos",
    "BR000365": "AMPLE N",
    "BR000572": "AMTS (All My Things)",
    "BR000659": "AMUSE",
    "BR000563": "And:ar",
    "BR000522": "ANN 365",
    "BR000516": "ANUA",
    "BR000181": "Apieu",
    "BR001129": "APLB",
    "BR000152": "APRIL SKIN",
    "BR000294": "aromatica",
    "BR000625": "ATHINGS",
    "BR000367": "ATOPALM",
    "BR000558": "ATVT",
    "BR000301": "Avajar",
    "BR000537": "AXIS-Y",
    }
    return brand_name_map.get(brand_cd, "Unknown Brand")

def handle_alert(driver):
    try:
        WebDriverWait(driver, 3).until(EC.alert_is_present())
        alert = driver.switch_to.alert
        alert.accept()
    except:
        pass

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ ---
def login_and_scrape(username, password):
    options = Options()
    options.add_argument('--disable-notifications')
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    driver.get("https://wholesale.stylekorean.com/Member/SignIn")
    handle_alert(driver)

    driver.find_element(By.ID, "user_id").send_keys(username)
    driver.find_element(By.ID, "pwd").send_keys(password)
    driver.find_element(By.CSS_SELECTOR, ".Btn_Login[type='submit']").click()
    handle_alert(driver)

    wb = Workbook()
    ws = wb.active
    ws.append([
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è",
        "MOQ", "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫", "in box", "–ê—Ä—Ç–∏–∫—É–ª", "Product code",
        "–¶–µ–Ω–∞ Discounted KRW", "Cena na site $", "Price", "Language", "Lower limit",
        "User group", "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏", "–°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ KRW","status","category","procent"
    ])

    file_path = '/Users/tyantamara/parser_stas_final_1.xlsx'

    # --- Google Drive ---
    gauth = GoogleAuth()
    gauth.LocalWebserverAuth()
    drive = GoogleDrive(gauth)
    folder_id = "10J-E4RcBJFfrdcqU_UAWask8BKTZ5Mw2"
    file_name = os.path.basename(file_path)

    brand_urls = [
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000357", # 9Wishes
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR001115", # ABEREDE
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000311", # Abib
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000067", # ACWELL
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000473", # AESTURA
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000457", # AHEADS
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000487", # AIRIVE
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000811", # AKF
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000502", # ALETHEIA
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR001097", # ALLIONE
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000081", # Amos
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000365", # AMPLE N
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000572", # AMTS (All My Things)
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000659", # AMUSE
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000563", # And:ar
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000522", # ANN 365
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000516", # ANUA
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000181", # Apieu
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR001129", # APLB
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000152", # APRIL SKIN
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000294", # aromatica
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000625", # ATHINGS
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000367", # ATOPALM
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000558", # ATVT
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000301", # Avajar
"https://wholesale.stylekorean.com/Product/BrandProduct?brand_cd=BR000537", # AXIS-Y

    ]

    for brand_url in brand_urls:
        brand_name = extract_brand_name(brand_url)
        print(f"Scraping products for brand: {brand_name}")

        driver.get(brand_url)
        handle_alert(driver)
        WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.CLASS_NAME, "album")))

        page_links = driver.find_elements(By.CLASS_NAME, "page-link")
        num_pages = len(page_links) if page_links else 1
        if len(page_links) >= 3:
            num_pages_element = page_links[-3]
            num_pages_label = num_pages_element.get_attribute("aria-label")
            if num_pages_label:
                num_pages = int(num_pages_label.split()[-1])

        for page_num in range(1, num_pages + 1):
            handle_alert(driver)
            WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.CLASS_NAME, "album")))
            soup = BeautifulSoup(driver.page_source, 'html.parser')

            product_cards = soup.find_all("div", class_="card mb-4 shadow-sm")
            for card in product_cards:
                try:
                    name = card.find("span", class_="productTxt").text.strip()
                    category = assign_category(name)
                    item_code = card.find("span", class_="productCodeTxt").text.split("SKU:")[1].strip()
                    quantity_availabl_element = card.find("span", class_="qtyTxt")
                    quantity_availabl = quantity_availabl_element.text.strip().replace('ea','').split()[0].replace(',','') if quantity_availabl_element else None
                    img_element = card.find("img", class_="Img_Product")
                    img_src = img_element.get('src') if img_element else None
                    moq_element = card.find("span", class_="moqTxt")
                    moq = moq_element.text.split(":")[-1].replace("ea","").strip() if moq_element else None
                    Product_code = card.find("span", class_="barcodeTxt").text.strip().split(":")[1].strip()
                    pieces_per_box_element = card.find("span", class_="boxCnt")
                    if pieces_per_box_element:
                        pieces_per_box = pieces_per_box_element.text.split(':')[-1].strip().replace('ea','').replace(')','').replace(',','')
                        if not pieces_per_box or pieces_per_box == '':
                            pieces_per_box = '20'
                    else:
                        pieces_per_box = '20'
                    price_discounted_element = card.find("span", class_="priceTxt")
                    price_discounted = price_discounted_element.text.strip().replace("KRW","").replace(",","").replace(".00","") if price_discounted_element else 0
                    price_discounted = float(price_discounted)
                    price_old_element = card.find("span", class_="priceOld2")
                    price_old = price_old_element.text.strip().replace("KRW","").replace(",","").replace(".00","") if price_old_element else None
                    if price_old:
                        price_old = float(price_old)
                    cena_na_site = round(price_discounted * 1.2 / 1250, 2)
                    price = round(price_discounted * 1.1 / 1250, 2)
                     # ‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É —Å –¥–µ—Å—è—Ç–∏—á–Ω–æ–π —Ç–æ—á–∫–æ–π
                    cena_na_site_str = f"{cena_na_site:.2f}".replace(",", ".")
                    price_str = f"{price:.2f}".replace(",", ".")

                    item_code_clean = re.sub(r'\s+', '', item_code)
                    product_code_clean = re.sub(r'\s+', '', Product_code)
                    status_value = f"–ë—Ä–µ–Ω–¥///{brand_name[0].upper()}///{brand_name}"
                    STATUS="A"
                    procent= round(price_discounted / price_old , 2) if price_old else 0

                    ws.append([
                        img_src, brand_name, name, category, 'ea', moq, quantity_availabl,
                        pieces_per_box, item_code_clean, product_code_clean, price_discounted,
                        cena_na_site_str, price_str, 'ru', pieces_per_box, '–í—Å–µ', '1', price_old,
                        STATUS, status_value, procent
                    ])
                except Exception as e:
                    print("Error parsing product:", e)

# --- –°–æ—Ö—Ä–∞–Ω—è–µ–º Excel –ª–æ–∫–∞–ª—å–Ω–æ ---
            try:
                wb.save(file_path)
                print(f"‚úÖ File saved successfully after page {page_num}")
            except Exception as e:
                print("‚ùå Error saving file:", e)

            # --- –ó–∞–≥—Ä—É–∂–∞–µ–º (–æ–±–Ω–æ–≤–ª—è–µ–º) –Ω–∞ Google Drive ---
            try:
                # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –ø–æ –∏–º–µ–Ω–∏
                query = f"'{folder_id}' in parents and trashed=false and title='{file_name}'"
                file_list = drive.ListFile({'q': query}).GetList()

                if file_list:
                    # ‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º
                    file_drive = file_list[0]
                    print(f"–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª '{file_name}', –æ–±–Ω–æ–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ...")
                else:
                    # ‚ùó –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
                    file_drive = drive.CreateFile({'title': file_name, 'parents': [{'id': folder_id}]})
                    print(f"–§–∞–π–ª '{file_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
                file_drive.SetContentFile(file_path)
                file_drive.Upload()
                print(f"‚úÖ –§–∞–π–ª '{file_name}' —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω –Ω–∞ Google Drive –ø–æ—Å–ª–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")

            except Exception as e:
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –Ω–∞ Google Drive:", e)

            # --- –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É ---
            if page_num < num_pages:
                try:
                    next_page_button = driver.find_element(By.XPATH, f"//a[@class='page-link' and @page='{page_num + 1}']")
                    next_page_button.click()
                except Exception as e:
                    print("‚ö†Ô∏è Error clicking next page:", e)
                    break

    driver.quit()
    print("üéØ Scraping completed.")

# --- –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ ---
login_and_scrape("beelifecos", "1983beelif")

